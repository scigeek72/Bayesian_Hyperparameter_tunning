{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMJQgAMmuPOXkpTybLvo1YG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/scigeek72/Bayesian_Hyperparameter_tunning/blob/main/Tune_XGBoost_classifier_with_Hyperopt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tunning hyper-parameters of a XGBoost classifier using Hyperopt package\n",
        "\n",
        "The primary objective of this blog post is to highlight the critical role of hyperparameter tuning in the process of model building. Based on my experience in the field, particularly in the application domain, it is evident that there is often an emphasis on the power of algorithms or models, without giving adequate attention to the importance of fine-tuning them to achieve optimal performance. Through this post, I aim to emphasize the significance of hyperparameter tuning and encourage readers to prioritize this critical step in their machine learning workflows.\n",
        "\n",
        "In this blog post, we will explore the use of the [Hyperopt package](https://github.com/hyperopt/hyperopt) for automatic hyperparameter tuning of a machine learning model. Specifically, we will use Hyperopt to tune a XGBoost classifier, although this methodology can also be applied to other types of classifiers or regressors. Hyperparameter tuning is a crucial step in machine learning, as it can significantly impact the performance of the model. While grid search and randomized search are commonly used optimization techniques, they have limitations such as being slow or underperforming. Bayesian optimization algorithms have emerged as a promising alternative to these traditional tuning algorithms. In this post, we will demonstrate how to use a Bayesian optimization algorithm provided by the Hyperopt package to optimize the hyperparameters of a XGBoost classifier for a classification task. We will begin by loading a dataset for classification."
      ],
      "metadata": {
        "id": "x-cdgKKUIKFJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading dataset\n",
        "\n",
        "We will load breast cancer data sets from scikit-learn."
      ],
      "metadata": {
        "id": "scp6LxYlIPC7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import datasets\n",
        "\n",
        "data = datasets.load_breast_cancer()"
      ],
      "metadata": {
        "id": "m7jo0uYbIOXK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iLh5K5-pIgvw",
        "outputId": "c33f2c79-2532-4b04-eab5-da51dc9a2745"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename', 'data_module'])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below we will investigate the dataset to get an idea about it, e.g. what are the feature names, what is the target, and if any cleaning is needed."
      ],
      "metadata": {
        "id": "FKipKmldI3Xg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(data['feature_names'])\n",
        "print(\"\\n**************************\\n\")\n",
        "print(data['target_names'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ssNpQ0I1ImW9",
        "outputId": "1dc20458-9b87-4e00-e69f-956606f4da27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['mean radius' 'mean texture' 'mean perimeter' 'mean area'\n",
            " 'mean smoothness' 'mean compactness' 'mean concavity'\n",
            " 'mean concave points' 'mean symmetry' 'mean fractal dimension'\n",
            " 'radius error' 'texture error' 'perimeter error' 'area error'\n",
            " 'smoothness error' 'compactness error' 'concavity error'\n",
            " 'concave points error' 'symmetry error' 'fractal dimension error'\n",
            " 'worst radius' 'worst texture' 'worst perimeter' 'worst area'\n",
            " 'worst smoothness' 'worst compactness' 'worst concavity'\n",
            " 'worst concave points' 'worst symmetry' 'worst fractal dimension']\n",
            "\n",
            "**************************\n",
            "\n",
            "['malignant' 'benign']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will replace the space between words in `feature_names` by '_'. This is my personal taste and is not necessary if not desired."
      ],
      "metadata": {
        "id": "PPv6TN-GJnJS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "feature_names = [x.replace(' ','_') for x in data['feature_names'].tolist()] "
      ],
      "metadata": {
        "id": "OZAKZiGcJMpn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "print(f\"Type of X is {type(X)}\\n Type of y is {type(y)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8LifQ78cMbH9",
        "outputId": "aa2f1d4d-a74d-4e81-81df-0f05e7aca88c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type of X is <class 'numpy.ndarray'>\n",
            " Type of y is <class 'numpy.ndarray'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the numpy arrays to pandas dataframe\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "X = pd.DataFrame(X,columns = feature_names)\n",
        "y = pd.DataFrame(y, columns = ['lable'])"
      ],
      "metadata": {
        "id": "baXZ9KBSM0iJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "tJDzAuqRNHX3",
        "outputId": "b47699a0-82b6-4184-ebd2-214ffc724c39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   mean_radius  mean_texture  mean_perimeter  mean_area  mean_smoothness  \\\n",
              "0        17.99         10.38          122.80     1001.0          0.11840   \n",
              "1        20.57         17.77          132.90     1326.0          0.08474   \n",
              "2        19.69         21.25          130.00     1203.0          0.10960   \n",
              "3        11.42         20.38           77.58      386.1          0.14250   \n",
              "4        20.29         14.34          135.10     1297.0          0.10030   \n",
              "\n",
              "   mean_compactness  mean_concavity  mean_concave_points  mean_symmetry  \\\n",
              "0           0.27760          0.3001              0.14710         0.2419   \n",
              "1           0.07864          0.0869              0.07017         0.1812   \n",
              "2           0.15990          0.1974              0.12790         0.2069   \n",
              "3           0.28390          0.2414              0.10520         0.2597   \n",
              "4           0.13280          0.1980              0.10430         0.1809   \n",
              "\n",
              "   mean_fractal_dimension  ...  worst_radius  worst_texture  worst_perimeter  \\\n",
              "0                 0.07871  ...         25.38          17.33           184.60   \n",
              "1                 0.05667  ...         24.99          23.41           158.80   \n",
              "2                 0.05999  ...         23.57          25.53           152.50   \n",
              "3                 0.09744  ...         14.91          26.50            98.87   \n",
              "4                 0.05883  ...         22.54          16.67           152.20   \n",
              "\n",
              "   worst_area  worst_smoothness  worst_compactness  worst_concavity  \\\n",
              "0      2019.0            0.1622             0.6656           0.7119   \n",
              "1      1956.0            0.1238             0.1866           0.2416   \n",
              "2      1709.0            0.1444             0.4245           0.4504   \n",
              "3       567.7            0.2098             0.8663           0.6869   \n",
              "4      1575.0            0.1374             0.2050           0.4000   \n",
              "\n",
              "   worst_concave_points  worst_symmetry  worst_fractal_dimension  \n",
              "0                0.2654          0.4601                  0.11890  \n",
              "1                0.1860          0.2750                  0.08902  \n",
              "2                0.2430          0.3613                  0.08758  \n",
              "3                0.2575          0.6638                  0.17300  \n",
              "4                0.1625          0.2364                  0.07678  \n",
              "\n",
              "[5 rows x 30 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4bceef12-27aa-4fea-aef1-088edbf1336c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean_radius</th>\n",
              "      <th>mean_texture</th>\n",
              "      <th>mean_perimeter</th>\n",
              "      <th>mean_area</th>\n",
              "      <th>mean_smoothness</th>\n",
              "      <th>mean_compactness</th>\n",
              "      <th>mean_concavity</th>\n",
              "      <th>mean_concave_points</th>\n",
              "      <th>mean_symmetry</th>\n",
              "      <th>mean_fractal_dimension</th>\n",
              "      <th>...</th>\n",
              "      <th>worst_radius</th>\n",
              "      <th>worst_texture</th>\n",
              "      <th>worst_perimeter</th>\n",
              "      <th>worst_area</th>\n",
              "      <th>worst_smoothness</th>\n",
              "      <th>worst_compactness</th>\n",
              "      <th>worst_concavity</th>\n",
              "      <th>worst_concave_points</th>\n",
              "      <th>worst_symmetry</th>\n",
              "      <th>worst_fractal_dimension</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.3001</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>...</td>\n",
              "      <td>25.38</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.1622</td>\n",
              "      <td>0.6656</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.0869</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>...</td>\n",
              "      <td>24.99</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.1866</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.1974</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>...</td>\n",
              "      <td>23.57</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.4245</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.2414</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>...</td>\n",
              "      <td>14.91</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.2098</td>\n",
              "      <td>0.8663</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.1980</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>...</td>\n",
              "      <td>22.54</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.1374</td>\n",
              "      <td>0.2050</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 30 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4bceef12-27aa-4fea-aef1-088edbf1336c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4bceef12-27aa-4fea-aef1-088edbf1336c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4bceef12-27aa-4fea-aef1-088edbf1336c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KPjOucVpNTRu",
        "outputId": "ea80d3d2-14ea-47c5-82fb-08ed01142c66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 569 entries, 0 to 568\n",
            "Data columns (total 30 columns):\n",
            " #   Column                   Non-Null Count  Dtype  \n",
            "---  ------                   --------------  -----  \n",
            " 0   mean_radius              569 non-null    float64\n",
            " 1   mean_texture             569 non-null    float64\n",
            " 2   mean_perimeter           569 non-null    float64\n",
            " 3   mean_area                569 non-null    float64\n",
            " 4   mean_smoothness          569 non-null    float64\n",
            " 5   mean_compactness         569 non-null    float64\n",
            " 6   mean_concavity           569 non-null    float64\n",
            " 7   mean_concave_points      569 non-null    float64\n",
            " 8   mean_symmetry            569 non-null    float64\n",
            " 9   mean_fractal_dimension   569 non-null    float64\n",
            " 10  radius_error             569 non-null    float64\n",
            " 11  texture_error            569 non-null    float64\n",
            " 12  perimeter_error          569 non-null    float64\n",
            " 13  area_error               569 non-null    float64\n",
            " 14  smoothness_error         569 non-null    float64\n",
            " 15  compactness_error        569 non-null    float64\n",
            " 16  concavity_error          569 non-null    float64\n",
            " 17  concave_points_error     569 non-null    float64\n",
            " 18  symmetry_error           569 non-null    float64\n",
            " 19  fractal_dimension_error  569 non-null    float64\n",
            " 20  worst_radius             569 non-null    float64\n",
            " 21  worst_texture            569 non-null    float64\n",
            " 22  worst_perimeter          569 non-null    float64\n",
            " 23  worst_area               569 non-null    float64\n",
            " 24  worst_smoothness         569 non-null    float64\n",
            " 25  worst_compactness        569 non-null    float64\n",
            " 26  worst_concavity          569 non-null    float64\n",
            " 27  worst_concave_points     569 non-null    float64\n",
            " 28  worst_symmetry           569 non-null    float64\n",
            " 29  worst_fractal_dimension  569 non-null    float64\n",
            "dtypes: float64(30)\n",
            "memory usage: 133.5 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets investigate the target column. "
      ],
      "metadata": {
        "id": "muFX4UtZNuZY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Number of cases labeled 1 is: {sum(y.lable == 1)}\\n\")\n",
        "\n",
        "print(f\"Number of cases labeled 0 is: {sum(y.lable == 0)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JyiYQQhbNbf1",
        "outputId": "2889fe8f-0b83-4461-c8e3-fd67a665fc00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of cases labeled 1 is: 357\n",
            "\n",
            "Number of cases labeled 0 is: 212\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "So, `Benign` is labeled as 1 and `Malignant` is labeled as 0"
      ],
      "metadata": {
        "id": "otlOTQ4qOoXJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nneg = sum(y.lable == 0)\n",
        "npos = sum(y.lable == 1)\n",
        "\n",
        "print(f\"The ratio of negative to positive cases is: {nneg/npos}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N0L6vt-7N2v-",
        "outputId": "20ee15a8-a8cb-44b5-dc48-b18e22994172"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The ratio of negative to positive cases is: 0.5938375350140056\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will split the dataset into train and test sets. We will set aside test set and only use it to evaluate the model. \n",
        "\n",
        "Also, we will use `StratifiedShuffleSplit` to make sure the `train` and `test` sets has the same positive and negative cases."
      ],
      "metadata": {
        "id": "DY4xxGNdQep_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pandas.core.common import random_state\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "\n",
        "ss = StratifiedShuffleSplit(2,test_size=0.2, random_state=44)\n",
        "for tr_idx,ts_idx in ss.split(X,y):\n",
        "  X_train, y_train = X.loc[tr_idx], y.loc[tr_idx]\n",
        "  X_test, y_test = X.loc[ts_idx], y.loc[ts_idx]\n",
        "\n",
        "print(f\"\\nShape of X_train is {X_train.shape}\")\n",
        "print(f\"\\nShape of X_test is {X_test.shape}\")\n",
        "print(f\"\\nLength of y_train is {y_train.shape}\")\n",
        "print(f\"\\nLength of y_test is {y_test.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PDpdll77PX8j",
        "outputId": "c473b33e-b3da-4f0a-9ab7-2d14da534859"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Shape of X_train is (455, 30)\n",
            "\n",
            "Shape of X_test is (114, 30)\n",
            "\n",
            "Length of y_train is (455, 1)\n",
            "\n",
            "Length of y_test is (114, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "# Build DMatrix (primarily to make processing faster) \n",
        "dtrain_clf = xgb.DMatrix(X_train, y_train, enable_categorical=True)\n",
        "dtest_clf = xgb.DMatrix(X_test, y_test, enable_categorical=True)"
      ],
      "metadata": {
        "id": "g_RXclEbRVIx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below we will cross-validate a model with default parameters. "
      ],
      "metadata": {
        "id": "ESc6H_XfSk2j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score, recall_score, confusion_matrix,roc_auc_score\n",
        "\n",
        "params_1 = {\"objective\": \"binary:logistic\"}\n",
        "\n",
        "n = 1000\n",
        "\n",
        "results = xgb.cv(params_1,\n",
        "                 dtrain_clf,\n",
        "                 num_boost_round = n,\n",
        "                 nfold=5,\n",
        "                 metrics = [\"logloss\",\"auc\",\"error\"],\n",
        "                 early_stopping_rounds=20\n",
        "                 )"
      ],
      "metadata": {
        "id": "MXeZJg5uRiRX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "id": "bvnGGhy1S1gM",
        "outputId": "cd361cf8-c634-4cad-e9c1-598f76407988"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   train-logloss-mean  train-logloss-std  train-auc-mean  train-auc-std  \\\n",
              "0            0.464040           0.004158        0.996691       0.002549   \n",
              "1            0.331266           0.002541        0.999291       0.000157   \n",
              "2            0.244992           0.002581        0.999695       0.000171   \n",
              "3            0.185390           0.002293        0.999820       0.000083   \n",
              "4            0.142205           0.002457        0.999887       0.000045   \n",
              "\n",
              "   train-error-mean  train-error-std  test-logloss-mean  test-logloss-std  \\\n",
              "0          0.024176         0.008223           0.486575          0.010266   \n",
              "1          0.008242         0.003885           0.365231          0.013975   \n",
              "2          0.007692         0.004396           0.284250          0.016925   \n",
              "3          0.006044         0.002056           0.233371          0.022338   \n",
              "4          0.003297         0.001099           0.197808          0.027032   \n",
              "\n",
              "   test-auc-mean  test-auc-std  test-error-mean  test-error-std  \n",
              "0       0.966609      0.026867         0.054945        0.028656  \n",
              "1       0.982045      0.014662         0.052747        0.027274  \n",
              "2       0.988781      0.010982         0.043956        0.023051  \n",
              "3       0.988673      0.011179         0.043956        0.024076  \n",
              "4       0.988299      0.011358         0.046154        0.022413  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3798a640-577a-44ea-980f-e79591e5cda5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>train-logloss-mean</th>\n",
              "      <th>train-logloss-std</th>\n",
              "      <th>train-auc-mean</th>\n",
              "      <th>train-auc-std</th>\n",
              "      <th>train-error-mean</th>\n",
              "      <th>train-error-std</th>\n",
              "      <th>test-logloss-mean</th>\n",
              "      <th>test-logloss-std</th>\n",
              "      <th>test-auc-mean</th>\n",
              "      <th>test-auc-std</th>\n",
              "      <th>test-error-mean</th>\n",
              "      <th>test-error-std</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.464040</td>\n",
              "      <td>0.004158</td>\n",
              "      <td>0.996691</td>\n",
              "      <td>0.002549</td>\n",
              "      <td>0.024176</td>\n",
              "      <td>0.008223</td>\n",
              "      <td>0.486575</td>\n",
              "      <td>0.010266</td>\n",
              "      <td>0.966609</td>\n",
              "      <td>0.026867</td>\n",
              "      <td>0.054945</td>\n",
              "      <td>0.028656</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.331266</td>\n",
              "      <td>0.002541</td>\n",
              "      <td>0.999291</td>\n",
              "      <td>0.000157</td>\n",
              "      <td>0.008242</td>\n",
              "      <td>0.003885</td>\n",
              "      <td>0.365231</td>\n",
              "      <td>0.013975</td>\n",
              "      <td>0.982045</td>\n",
              "      <td>0.014662</td>\n",
              "      <td>0.052747</td>\n",
              "      <td>0.027274</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.244992</td>\n",
              "      <td>0.002581</td>\n",
              "      <td>0.999695</td>\n",
              "      <td>0.000171</td>\n",
              "      <td>0.007692</td>\n",
              "      <td>0.004396</td>\n",
              "      <td>0.284250</td>\n",
              "      <td>0.016925</td>\n",
              "      <td>0.988781</td>\n",
              "      <td>0.010982</td>\n",
              "      <td>0.043956</td>\n",
              "      <td>0.023051</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.185390</td>\n",
              "      <td>0.002293</td>\n",
              "      <td>0.999820</td>\n",
              "      <td>0.000083</td>\n",
              "      <td>0.006044</td>\n",
              "      <td>0.002056</td>\n",
              "      <td>0.233371</td>\n",
              "      <td>0.022338</td>\n",
              "      <td>0.988673</td>\n",
              "      <td>0.011179</td>\n",
              "      <td>0.043956</td>\n",
              "      <td>0.024076</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.142205</td>\n",
              "      <td>0.002457</td>\n",
              "      <td>0.999887</td>\n",
              "      <td>0.000045</td>\n",
              "      <td>0.003297</td>\n",
              "      <td>0.001099</td>\n",
              "      <td>0.197808</td>\n",
              "      <td>0.027032</td>\n",
              "      <td>0.988299</td>\n",
              "      <td>0.011358</td>\n",
              "      <td>0.046154</td>\n",
              "      <td>0.022413</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3798a640-577a-44ea-980f-e79591e5cda5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3798a640-577a-44ea-980f-e79591e5cda5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3798a640-577a-44ea-980f-e79591e5cda5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We asked `xgb.cv()` to track three metrics on the hold-out validation set. The `results` dataframe contains the values of these metrics on each split of the cross-validation. The column header is very informative. As you can see `test-auc-mean` is the column we will consider."
      ],
      "metadata": {
        "id": "hVWttAlTTgDf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(results['test-auc-mean'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "eL6L2dKzS88Y",
        "outputId": "eb902f86-a585-474d-d434-5ddafbee418c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7ff5f3758670>]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We see that even for a model with only default parameters, the cross validated `auc` score reaches 0.985. This is pretty good. \n",
        "\n",
        "But the real test of the model lies when it is used to predict on the test set. \n",
        "\n",
        "`xgb.cv()` doesn't give a classifier object. So, next we will train a xgb classifier object on the entire training set and then test it."
      ],
      "metadata": {
        "id": "CJjX-RL0VDJJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clf_1 = xgb.XGBClassifier(**params_1)\n",
        "\n",
        "clf_1.fit(X_train,y_train)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "id": "TUngTZRHT9tA",
        "outputId": "d5bb3693-dfaf-4695-ad2c-0d3005d6fa21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=None, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
              "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
              "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
              "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
              "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
              "              predictor=None, random_state=None, ...)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=None, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
              "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
              "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
              "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
              "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
              "              predictor=None, random_state=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=None, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
              "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
              "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
              "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
              "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
              "              predictor=None, random_state=None, ...)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred_1 = clf_1.predict(X_test)"
      ],
      "metadata": {
        "id": "HWc4b8Y3WINP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"f1 score : {f1_score(y_test, pred_1)}\\n\")\n",
        "print(f\"confusion Matrix\\n: {confusion_matrix(y_test, pred_1)}\\n\")\n",
        "print(f\"auc score: {roc_auc_score(y_test, pred_1)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lQNzqJanW49C",
        "outputId": "095b06a7-2cbf-46d7-9a8f-bba767c3859e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "f1 score : 0.9600000000000001\n",
            "\n",
            "confusion Matrix\n",
            ": [[36  6]\n",
            " [ 0 72]]\n",
            "\n",
            "auc score: 0.9285714285714286\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "On the held out test set, we hit a f1_score of .96 which is pretty good, particularly when we are basically using the default parameters. Now the question is can we improve it? \n",
        "\n",
        "A google search would reveal several posts which talks about tunning the hyper-parameters of this model. However, since `XGBClassifier` (and `XGBRegressor`) has so many hyper-parameters available, it is initially hard to pick and choose. This choice obviously depends on the data. \n",
        "\n",
        "Since we don't have any apriory knowledge about it, we will \"go full monty\" and tune all the hyper-parameters that are available to us. \n",
        "\n"
      ],
      "metadata": {
        "id": "itcY825e26Ua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# A brief over view of the optimization procedure\n",
        "\n",
        "In this blog post, we will explore the use of the [Hyperopt library](https://github.com/hyperopt/hyperopt) to optimize an XGBoost classifier. Hyperopt utilizes Bayesian optimization techniques to solve the hyperparameter optimization problem. To use Hyperopt, users must provide a \"search space\" for the hyperparameters they wish to optimize in order to find the best classifier performance. Hyperopt then builds a probabilistic model based on this search space, selecting random points and creating a \"good\" and a \"bad\" region of the space depending on the performance of the machine learning model. It then constructs a joint probability distribution over these regions, sampling points from the space to evaluate the machine learning model. This process is repeated multiple times until some stopping condition is reached, using the Tree-Structured Parzen estimator algorithm.  Interested readers can look at [Making a Science of Model Search: Hyperparameter Optimization in Hundreds of Dimensions for Vision Architectures](http://proceedings.mlr.press/v28/bergstra13.pdf) and the references therein for a more thorough understanding.\n",
        "\n",
        "To use Hyperopt, we require a search space (user-defined), an objective function, and the use of the fmin() function to minimize the objective function over the search space. Hyperopt uses a Trials object to keep track of all the results of the experiments.\n",
        "\n",
        " - The **search space** defines all the parameters we want to optimize, along with their range and the probability distributions (if desired) that we think the algorithm should sample from during optimization. Hyperopt defines these distributions in the hp object.\n",
        "\n",
        " - In the **objective function**, we define the machine learning algorithm we are interested in (in our case, the XGBoost classifier), along with an evaluation metric that the fmin() function uses during optimization to keep track of the performance. If the evaluation metric is something like F1 score, it should be multiplied by (-1) for minimization.\n",
        "\n",
        " - The `fmin()` function is the engine that drives the optimization process. The minimum set of arguments required for this function are the search space, objective function, Trials object, the algorithm to use (TPE, for example), and the maximum number of iterations (max_eval). An early stopping criterion can also be defined. If users want the values where the minimum value is reached given the search criterion, they should set the `return_argmin` argument to `False`; otherwise, it will return the position (in the array) where the minimum value is attained.\n",
        "\n",
        "\n",
        "It is important to note that this procedure returns a set of hyperparameter values that it thinks optimize the machine learning model given the search space and the data. We must use these values to define the model again on the training set. Furthermore, it is recommended to run a cross-validation procedure inside the objective function rather than utilizing the test set to learn the optimal hyperparameters.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "RBa8XhnyR-Gr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Full set of parameters"
      ],
      "metadata": {
        "id": "Gq4axpIb9X8F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below is the search space with **most** of the tunable parameters included. We are utilizing `hyperopt` library to tune our parameters. There are other packages available, for example, `scikit-opt` etc that utilizes a different optimization engine than hyperopt. \n",
        "\n"
      ],
      "metadata": {
        "id": "_8l3hnh2VKzp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from hyperopt import STATUS_OK, Trials, fmin, hp, tpe, space_eval\n",
        "from hyperopt.early_stop import no_progress_loss"
      ],
      "metadata": {
        "id": "6oecBiiaZykN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "search_space = {\n",
        "    'max_depth': hp.choice(\"max_depth\", np.arange(1,20,1,dtype=int)),\n",
        "    'eta'      : hp.uniform(\"eta\", 0, 1),\n",
        "    'gamma'    : hp.uniform(\"gamma\", 0, 10e1),\n",
        "    'reg_alpha': hp.uniform(\"reg_alpha\", 10e-7, 10),\n",
        "    'reg_lambda' : hp.uniform(\"reg_lambda\", 0,1),\n",
        "    'colsample_bytree': hp.uniform(\"colsample_bytree\", 0.5,1),\n",
        "    'colsample_bynode': hp.uniform(\"colsample_bynode\", 0.5,1), \n",
        "    'colsample_bylevel': hp.uniform(\"colsample_bylevel\", 0.5,1),\n",
        "    'n_estimators': hp.choice(\"n_estimators\", np.arange(100,1000,10,dtype='int')),\n",
        "    'min_child_weight' : hp.choice(\"min_child_weight\", np.arange(1,10,1,dtype='int')),\n",
        "    'max_delta_step' : hp.choice(\"max_delta_step\", np.arange(1,10,1,dtype='int')),\n",
        "    'subsample' : hp.uniform(\"subsample\",0.5,1),\n",
        "    'objective' : 'binary:logistic',\n",
        "    'eval_metric' : 'aucpr',\n",
        "    #'scale_pos_weight' : hp.uniform('scale_pos_weight', np.ceil(nneg/npos - 2), np.ceil(nneg/npos + 10)),\n",
        "    'seed' : 44\n",
        "}"
      ],
      "metadata": {
        "id": "JMEPMzo2X2Sb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we have defined a search space for **xgbClassifier**, we will go ahead and define the objective function. \n",
        "\n",
        "Note, I will define it in 3 slightly different ways but utilize the last one as I like it over the rest as it utilizes xgboost's `cv()` function. Though for our toy example we could have used the other functions, for large datasets would significantly improve performance. \n",
        "\n",
        "Also note that the objective function should return a dictionary with `loss` and `status` keys **must** be included in the dictorary. There are some other keys that you can include as well (see the hyperopt documentation referenced above) but to keep things simple, we use the bare minimum that is needed for the hyperopt to work. \n",
        "\n",
        "Hyperopt minimizes the objective function by monitoring the loss function. So if the evaluation metric used is something that is needed to be maximized, then it needs to be multiplied by (-1) as is done below ( maximizing a quantity is same as minimizing the negative of that quantity). "
      ],
      "metadata": {
        "id": "LgXQLzM8XHVQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def objective(space):\n",
        "  clf = xgb.XGBRFClassifier(**space)\n",
        "  evaluation = [(X_train, y_train),(X_test, y_test)]\n",
        "  clf.fit(X_train, y_train)\n",
        "  pred = clf.predict(X_test)\n",
        "  f1_ = f1_score(y_test, pred)\n",
        "  return {'loss': -f1_, 'status': STATUS_OK}\n",
        "\n",
        "\n",
        "def new_objective(space):\n",
        "  clf = xgb.XGBClassifier(**space)\n",
        "  cv_score = cross_val_score(estimator=clf, X = X_train, y=y_train, cv=5, scoring='f1')\n",
        "  f1_ = np.mean(cv_score)\n",
        "  return {'loss':-f1_, 'status':STATUS_OK}\n",
        "\n",
        "def xgb_objective(space):\n",
        "  results = xgb.cv(space, dtrain=dtrain_clf, num_boost_round=500, nfold=5, stratified=True, early_stopping_rounds=20,\n",
        "                   metrics = ['logloss','auc','aucpr','error'])\n",
        "  \n",
        "  best_score = results['test-auc-mean'].max()\n",
        "  return {'loss':-best_score, 'status': STATUS_OK}"
      ],
      "metadata": {
        "id": "hC-QzWWtXuWa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we have already defined the objective function, we will go ahead and get the best parameters using the `fmin` function of the hyperopt package. "
      ],
      "metadata": {
        "id": "q-D_S9CtZRwt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trials = Trials()\n",
        "\n",
        "best_hyperparams = fmin(fn=xgb_objective, space=search_space,algo=tpe.suggest,max_evals=500,trials=trials, return_argmin=False, early_stop_fn=no_progress_loss(10))\n",
        "\n",
        "best_params = best_hyperparams.copy()\n",
        "\n",
        "if 'eval_metric' in best_params:\n",
        "  best_params = {key:best_params[key] for key in best_params if key!='eval_metric'}\n",
        "\n",
        "best_params"
      ],
      "metadata": {
        "id": "sZfWOFipZQvW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have obtained a set of best parameters. Now we will build the classifier and test on the test set. "
      ],
      "metadata": {
        "id": "MWvXbr5daS9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clf_2 = xgb.XGBClassifier(**best_params)\n",
        "clf_2.fit(X_train, y_train)\n",
        "\n",
        "pred_2 = clf_2.predict(X_test)\n",
        "\n",
        "print(f\"f1 score : {f1_score(y_test, pred_2)}\\n\")\n",
        "print(f\"confusion Matrix\\n: {confusion_matrix(y_test, pred_2)}\\n\")\n",
        "print(f\"auc score: {roc_auc_score(y_test, pred_2)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SRW693QiafJh",
        "outputId": "f7f05f1e-1c9d-47a5-d200-e24654713b87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "f1 score : 0.9403973509933775\n",
            "\n",
            "confusion Matrix\n",
            ": [[34  8]\n",
            " [ 1 71]]\n",
            "\n",
            "auc score: 0.8978174603174603\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Oppss!!! Note that our performance dropped compared to default parameters where the f1 score was 0.960. But why? Afterall, we optimized the parameters and during optimization only used cross-validation on the training set to keep information leakage from test set into our model. \n",
        "\n",
        "Then why is the performance drop? This shows that with all these hyperparameters tuned based on the training set, the model learned **too much** of the training set and failed to generalize. A classic case of **overfitting** happening right infront of our eyes. \n",
        "\n",
        "One possible reason, could be the number of hyperparameters we chose to tune. It seems that since we tuned all possible tunable parameters, it may have backfired. \n",
        "\n",
        "At this point, redo the above experiments by removing one hyper-parmeters at a time and see if that imroves the f1 score above the default score.\n",
        "\n",
        "After playing around with the hyper-parameters and their ranges, I hit upon the the following search space.\n",
        "\n",
        "Lets see how we do."
      ],
      "metadata": {
        "id": "VT5sRvH3a_Ch"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "search_space_3 = {\n",
        "    #'max_depth': hp.choice(\"max_depth\", np.arange(1,20,1,dtype=int)),\n",
        "    'eta'      : hp.uniform(\"eta\", 0, 1),\n",
        "    'gamma'    : 0,#hp.uniform(\"gamma\", 0, 1),\n",
        "    #'reg_alpha': hp.uniform(\"reg_alpha\", 10e-7, 1),\n",
        "    'reg_lambda' : hp.uniform(\"reg_lambda\", 0,1),\n",
        "    'n_estimators': hp.choice(\"n_estimators\", np.arange(100,1000,10,dtype='int')),\n",
        "    #'min_child_weight' : hp.choice(\"min_child_weight\", np.arange(1,10,1,dtype='int')),\n",
        "    'objective' : 'binary:logistic',\n",
        "    'eval_metric' : 'auc',\n",
        "    #'scale_pos_weight' : hp.uniform('scale_pos_weight', np.ceil(nneg/npos - 2), np.ceil(nneg/npos + 10)),\n",
        "    'seed' : 44\n",
        "}"
      ],
      "metadata": {
        "id": "O0s1enB_c7jb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trials = Trials()\n",
        "\n",
        "best_hyperparams = fmin(fn=xgb_objective, \n",
        "                        space=search_space_3,\n",
        "                        algo=tpe.suggest, \n",
        "                        max_evals=500,\n",
        "                        trials=trials, \n",
        "                        return_argmin=False, \n",
        "                        early_stop_fn=no_progress_loss(10))\n",
        "\n",
        "best_params_3 = best_hyperparams.copy()\n",
        "\n",
        "if 'eval_metric' in best_params_3:\n",
        "  best_params_3 = {key:best_params_3[key] for key in best_params_3 if key!='eval_metric'}\n",
        "\n",
        "best_params_3"
      ],
      "metadata": {
        "id": "yp9-9GLa75tZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf_3 = xgb.XGBClassifier(**best_params_3)\n",
        "clf_3.fit(X_train, y_train)\n",
        "\n",
        "pred_3 = clf_3.predict(X_test)\n",
        "\n",
        "print(f\"f1 score : {f1_score(y_test, pred_3)}\\n\")\n",
        "print(f\"confusion Matrix\\n: {confusion_matrix(y_test, pred_3)}\\n\")\n",
        "print(f\"auc score: {roc_auc_score(y_test, pred_3)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nE4I4j-_8t6-",
        "outputId": "df9f77bb-9407-4b29-f1ce-9342f47def46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "f1 score : 0.9664429530201343\n",
            "\n",
            "confusion Matrix\n",
            ": [[37  5]\n",
            " [ 0 72]]\n",
            "\n",
            "auc score: 0.9404761904761905\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice, with this combination of hyper-parameters and their values, f1 score exceeds the f1 score with default hyper-parameters. Also note the value of the hyper-parameter `gamma` ( Î³ ). It is set to 0. Î³ is an important hyper-parameter for xgboost. A good blog post about tunning hyper-parameters and a discussion of the effect of Î³ on the model can be found in this medium article [here](https://medium.com/data-design/xgboost-hi-im-gamma-what-can-i-do-for-you-and-the-tuning-of-regularization-a42ea17e6ab6). "
      ],
      "metadata": {
        "id": "3aF3nbZI9EAy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclusion\n",
        "\n",
        "In conclusion, the process of tuning hyperparameters for a XGBoost classifier can be a daunting task with so many different tunable hyper-parameter available to the user. As demonstrated in this post, Bayesian optimization algorithms provided by the Hyperopt package offer a promising alternative to traditional tuning algorithms such as grid search or randomized search. By following the example and guidelines provided in this post, we hope that readers will gain a better understanding of the process of hyperparameter tuning and be able to optimize their XGBoost classifiers effectively.\n",
        "\n",
        "As stated in the begining of this article, the primary focus of this post is to highlight the importance of hyperparameter tuning for all machine learning models (and not just for xgboost classifier). I hope that readers will find this information useful and will be able to adopt it in their own work to optimize the performance of their machine learning models. "
      ],
      "metadata": {
        "id": "SskRxnqX_-5L"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YPLvokNUGcLG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}